import json
import os
import time
from dotenv import load_dotenv
from openai import OpenAI
from supabase import create_client, Client

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('.env.local')

SUPABASE_URL = os.getenv("SUPABASE_URL") or os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY_FOR_EMBEDDING") or os.getenv("OPENAI_API_KEY")

if not all([SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]):
    raise ValueError("è¯·ç¡®ä¿ .env.local æ–‡ä»¶ä¸­å·²è®¾ç½®æ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡ã€‚")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
print("æ­£åœ¨åˆå§‹åŒ– Supabase å’Œ OpenAI å®¢æˆ·ç«¯...")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
openai_client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url="https://api.openai.com/v1",
)
print("å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼")

def find_node_by_id(node_id, all_nodes):
    """æ ¹æ®IDæŸ¥æ‰¾èŠ‚ç‚¹"""
    for node in all_nodes:
        if node.get("id") == node_id:
            return node
    return None

def generate_base_node_text(node):
    """ç”ŸæˆèŠ‚ç‚¹çš„åŸºç¡€æ–‡æœ¬æè¿°"""
    props = node.get("properties", {})
    name = props.get("name")
    description = props.get("description")
    labels = node.get("labels", ["Thing"])
    label = labels[0] if labels else "Thing"
    
    # æ ¹æ®æ ‡ç­¾ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
    if label == "Module":
        if name and description:
            return f"è™šå¹»å¼•æ“æ¨¡å—'{name}': {description}"
        elif name:
            return f"è™šå¹»å¼•æ“æ¨¡å—'{name}'ï¼Œè¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ¨¡å—ã€‚"
    elif label == "System":
        if name and description:
            return f"è™šå¹»å¼•æ“ç³»ç»Ÿ'{name}': {description}"
        elif name:
            return f"è™šå¹»å¼•æ“ç³»ç»Ÿ'{name}'ï¼Œè¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿçº§ç»„ä»¶ã€‚"
    elif label == "Class":
        if name and description:
            return f"è™šå¹»å¼•æ“ç±»'{name}': {description}"
        elif name:
            return f"è™šå¹»å¼•æ“ç±»'{name}'ï¼Œè¿™æ˜¯ä¸€ä¸ªç±»å®šä¹‰ã€‚"
    elif label == "Interface":
        if name and description:
            return f"è™šå¹»å¼•æ“æ¥å£'{name}': {description}"
        elif name:
            return f"è™šå¹»å¼•æ“æ¥å£'{name}'ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¥å£å®šä¹‰ã€‚"
    elif label == "Subsystem":
        if name and description:
            return f"è™šå¹»å¼•æ“å­ç³»ç»Ÿ'{name}': {description}"
        elif name:
            return f"è™šå¹»å¼•æ“å­ç³»ç»Ÿ'{name}'ï¼Œè¿™æ˜¯ä¸€ä¸ªå­ç³»ç»Ÿç»„ä»¶ã€‚"
    else:
        if name and description:
            return f"å…³äºè™šå¹»å¼•æ“çš„'{name}' ({label}): {description}"
        elif name:
            return f"è™šå¹»å¼•æ“ä¸­æœ‰ä¸€ä¸ªæ¦‚å¿µæˆ–åŠŸèƒ½å«åš'{name}' ({label})ã€‚"
        else:
            return None

def enhance_node_with_relationships(node, all_relationships, all_nodes):
    """ä¸ºèŠ‚ç‚¹æ·»åŠ å…³ç³»ä¿¡æ¯ï¼Œç”Ÿæˆå¢å¼ºçš„æ–‡æœ¬æè¿°"""
    base_text = generate_base_node_text(node)
    if not base_text:
        return None
    
    node_id = node.get("id")
    dependencies = []
    dependents = []
    hierarchy_info = []
    
    # æŸ¥æ‰¾ä¸æ­¤èŠ‚ç‚¹ç›¸å…³çš„å…³ç³»
    for rel in all_relationships:
        if rel.get("start", {}).get("id") == node_id:
            # å½“å‰èŠ‚ç‚¹æ˜¯å…³ç³»çš„èµ·å§‹ç‚¹ï¼ˆä¾èµ–å…¶ä»–æ¨¡å—ï¼‰
            target_id = rel.get("end", {}).get("id")
            rel_type = rel.get("label")
            rel_props = rel.get("properties", {})
            dependency_type = rel_props.get("type", "")
            target_node = find_node_by_id(target_id, all_nodes)
            if target_node:
                target_name = target_node.get("properties", {}).get("name")
                target_labels = target_node.get("labels", [])
                if target_name:
                    # æ ¹æ®ä¾èµ–ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
                    if dependency_type == "PublicDependencyModuleNames":
                        dependencies.append(f"å…¬å¼€ä¾èµ–'{target_name}'")
                    elif dependency_type == "PrivateDependencyModuleNames":
                        dependencies.append(f"ç§æœ‰ä¾èµ–'{target_name}'")
                    elif dependency_type == "PublicIncludePathModuleNames":
                        dependencies.append(f"å…¬å¼€åŒ…å«è·¯å¾„ä¾èµ–'{target_name}'")
                    elif dependency_type == "PrivateIncludePathModuleNames":
                        dependencies.append(f"ç§æœ‰åŒ…å«è·¯å¾„ä¾èµ–'{target_name}'")
                    else:
                        dependencies.append(f"ä¾èµ–'{target_name}'")
                    
        elif rel.get("end", {}).get("id") == node_id:
            # å½“å‰èŠ‚ç‚¹æ˜¯å…³ç³»çš„ç»ˆæ­¢ç‚¹ï¼ˆè¢«å…¶ä»–æ¨¡å—ä¾èµ–ï¼‰
            source_id = rel.get("start", {}).get("id")
            rel_type = rel.get("label")
            rel_props = rel.get("properties", {})
            dependency_type = rel_props.get("type", "")
            source_node = find_node_by_id(source_id, all_nodes)
            if source_node:
                source_name = source_node.get("properties", {}).get("name")
                source_labels = source_node.get("labels", [])
                if source_name:
                    # æ ¹æ®ä¾èµ–ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
                    if dependency_type == "PublicDependencyModuleNames":
                        dependents.append(f"è¢«'{source_name}'å…¬å¼€ä¾èµ–")
                    elif dependency_type == "PrivateDependencyModuleNames":
                        dependents.append(f"è¢«'{source_name}'ç§æœ‰ä¾èµ–")
                    elif dependency_type == "PublicIncludePathModuleNames":
                        dependents.append(f"è¢«'{source_name}'å…¬å¼€åŒ…å«è·¯å¾„ä¾èµ–")
                    elif dependency_type == "PrivateIncludePathModuleNames":
                        dependents.append(f"è¢«'{source_name}'ç§æœ‰åŒ…å«è·¯å¾„ä¾èµ–")
                    else:
                        dependents.append(f"è¢«'{source_name}'ä¾èµ–")
    
    # æ·»åŠ å±‚æ¬¡ç»“æ„ä¿¡æ¯
    node_labels = node.get("labels", [])
    if "System" in node_labels:
        hierarchy_info.append("è¿™æ˜¯ä¸€ä¸ªç³»ç»Ÿçº§ç»„ä»¶")
    elif "Subsystem" in node_labels:
        hierarchy_info.append("è¿™æ˜¯ä¸€ä¸ªå­ç³»ç»Ÿç»„ä»¶")
    elif "Module" in node_labels:
        hierarchy_info.append("è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ¨¡å—")
    elif "Class" in node_labels:
        hierarchy_info.append("è¿™æ˜¯ä¸€ä¸ªç±»å®šä¹‰")
    elif "Interface" in node_labels:
        hierarchy_info.append("è¿™æ˜¯ä¸€ä¸ªæ¥å£å®šä¹‰")
    
    # ç»„åˆæœ€ç»ˆæ–‡æœ¬
    relationship_text = []
    if dependencies:
        relationship_text.append("å®ƒ" + "ï¼Œ".join(dependencies))
    if dependents:
        relationship_text.append("ï¼Œ".join(dependents))
    if hierarchy_info:
        relationship_text.append("ï¼Œ".join(hierarchy_info))
    
    if relationship_text:
        base_text += " " + "ï¼Œ".join(relationship_text) + "ã€‚"
    
    return base_text

def generate_relationship_text(relationship, all_nodes):
    """ä¸ºå…³ç³»ç”Ÿæˆç‹¬ç«‹çš„æè¿°æ–‡æœ¬"""
    rel_type = relationship.get("label")
    rel_props = relationship.get("properties", {})
    dependency_type = rel_props.get("type", "")
    start_node = relationship.get("start", {})
    end_node = relationship.get("end", {})
    
    start_name = start_node.get("properties", {}).get("name")
    end_name = end_node.get("properties", {}).get("name")
    
    if start_name and end_name:
        # æ ¹æ®ä¾èµ–ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
        if dependency_type == "PublicDependencyModuleNames":
            return f"åœ¨è™šå¹»å¼•æ“ä¸­ï¼Œ'{start_name}' å…¬å¼€ä¾èµ– '{end_name}'ï¼Œè¿™æ„å‘³ç€'{start_name}'å¯ä»¥è®¿é—®'{end_name}'çš„å…¬å…±æ¥å£ã€‚"
        elif dependency_type == "PrivateDependencyModuleNames":
            return f"åœ¨è™šå¹»å¼•æ“ä¸­ï¼Œ'{start_name}' ç§æœ‰ä¾èµ– '{end_name}'ï¼Œè¿™æ„å‘³ç€'{start_name}'å¯ä»¥è®¿é—®'{end_name}'çš„å†…éƒ¨å®ç°ã€‚"
        elif dependency_type == "PublicIncludePathModuleNames":
            return f"åœ¨è™šå¹»å¼•æ“ä¸­ï¼Œ'{start_name}' å…¬å¼€åŒ…å«è·¯å¾„ä¾èµ– '{end_name}'ï¼Œè¿™æ„å‘³ç€'{start_name}'å¯ä»¥åŒ…å«'{end_name}'çš„å…¬å…±å¤´æ–‡ä»¶ã€‚"
        elif dependency_type == "PrivateIncludePathModuleNames":
            return f"åœ¨è™šå¹»å¼•æ“ä¸­ï¼Œ'{start_name}' ç§æœ‰åŒ…å«è·¯å¾„ä¾èµ– '{end_name}'ï¼Œè¿™æ„å‘³ç€'{start_name}'å¯ä»¥åŒ…å«'{end_name}'çš„å†…éƒ¨å¤´æ–‡ä»¶ã€‚"
        else:
            return f"åœ¨è™šå¹»å¼•æ“ä¸­ï¼Œ'{start_name}' {rel_type} '{end_name}'ã€‚"
    
    return None

def generate_hierarchy_and_type_documents(all_nodes, all_relationships):
    """ç”Ÿæˆå±‚æ¬¡ç»“æ„å’Œç±»å‹å…³ç³»çš„é¢å¤–æ–‡æ¡£"""
    documents = []
    
    # æŒ‰æ ‡ç­¾åˆ†ç»„èŠ‚ç‚¹
    nodes_by_label = {}
    for node in all_nodes:
        labels = node.get("labels", [])
        for label in labels:
            if label not in nodes_by_label:
                nodes_by_label[label] = []
            nodes_by_label[label].append(node)
    
    # ç”Ÿæˆå±‚æ¬¡ç»“æ„æ–‡æ¡£
    if "System" in nodes_by_label:
        system_nodes = nodes_by_label["System"]
        if len(system_nodes) > 0:
            system_names = [node.get("properties", {}).get("name", "æœªçŸ¥") for node in system_nodes if node.get("properties", {}).get("name")]
            if system_names:
                hierarchy_text = f"è™šå¹»å¼•æ“åŒ…å«ä»¥ä¸‹ç³»ç»Ÿçº§ç»„ä»¶: {', '.join(system_names)}ã€‚è¿™äº›ç³»ç»Ÿæ˜¯å¼•æ“çš„æ ¸å¿ƒæ¶æ„ç»„ä»¶ï¼Œè´Ÿè´£ç®¡ç†ä¸åŒçš„åŠŸèƒ½é¢†åŸŸã€‚"
                documents.append(hierarchy_text)
    
    if "Subsystem" in nodes_by_label:
        subsystem_nodes = nodes_by_label["Subsystem"]
        if len(subsystem_nodes) > 0:
            subsystem_names = [node.get("properties", {}).get("name", "æœªçŸ¥") for node in subsystem_nodes if node.get("properties", {}).get("name")]
            if subsystem_names:
                hierarchy_text = f"è™šå¹»å¼•æ“åŒ…å«ä»¥ä¸‹å­ç³»ç»Ÿç»„ä»¶: {', '.join(subsystem_names)}ã€‚è¿™äº›å­ç³»ç»Ÿæ˜¯ç³»ç»Ÿçº§ç»„ä»¶çš„å­ç»„ä»¶ï¼Œæä¾›æ›´ç»†ç²’åº¦çš„åŠŸèƒ½ã€‚"
                documents.append(hierarchy_text)
    
    if "Module" in nodes_by_label:
        module_nodes = nodes_by_label["Module"]
        if len(module_nodes) > 0:
            module_names = [node.get("properties", {}).get("name", "æœªçŸ¥") for node in module_nodes if node.get("properties", {}).get("name")]
            if module_names:
                hierarchy_text = f"è™šå¹»å¼•æ“åŒ…å«ä»¥ä¸‹åŠŸèƒ½æ¨¡å—: {', '.join(module_names[:20])}{'...' if len(module_names) > 20 else ''}ã€‚è¿™äº›æ¨¡å—æ˜¯å¼•æ“çš„åŠŸèƒ½å•å…ƒï¼Œæ¯ä¸ªæ¨¡å—è´Ÿè´£ç‰¹å®šçš„åŠŸèƒ½é¢†åŸŸã€‚"
                documents.append(hierarchy_text)
    
    # ç”Ÿæˆç±»å‹å…³ç³»æ–‡æ¡£
    if "Class" in nodes_by_label:
        class_nodes = nodes_by_label["Class"]
        if len(class_nodes) > 0:
            class_names = [node.get("properties", {}).get("name", "æœªçŸ¥") for node in class_nodes if node.get("properties", {}).get("name")]
            if class_names:
                type_text = f"è™šå¹»å¼•æ“åŒ…å«ä»¥ä¸‹ç±»å®šä¹‰: {', '.join(class_names[:20])}{'...' if len(class_names) > 20 else ''}ã€‚è¿™äº›ç±»æä¾›äº†å¼•æ“çš„é¢å‘å¯¹è±¡ç¼–ç¨‹æ¥å£ã€‚"
                documents.append(type_text)
    
    if "Interface" in nodes_by_label:
        interface_nodes = nodes_by_label["Interface"]
        if len(interface_nodes) > 0:
            interface_names = [node.get("properties", {}).get("name", "æœªçŸ¥") for node in interface_nodes if node.get("properties", {}).get("name")]
            if interface_names:
                type_text = f"è™šå¹»å¼•æ“åŒ…å«ä»¥ä¸‹æ¥å£å®šä¹‰: {', '.join(interface_names)}ã€‚è¿™äº›æ¥å£å®šä¹‰äº†ç±»ä¹‹é—´çš„å¥‘çº¦å’ŒæŠ½è±¡ã€‚"
                documents.append(type_text)
    
    return documents

def migrate_data(json_file_path):
    print(f"å¼€å§‹å¤„ç†JSON Linesæ–‡ä»¶: {json_file_path}")
    
    # å­˜å‚¨æ‰€æœ‰æ•°æ®
    all_nodes = []
    all_relationships = []
    documents_to_insert = []
    
    # ç¬¬ä¸€æ­¥ï¼šè¯»å–æ‰€æœ‰æ•°æ®
    print("æ­£åœ¨è¯»å–èŠ‚ç‚¹å’Œå…³ç³»æ•°æ®...")
    with open(json_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                item = json.loads(line)
                if item.get("type") == "node":
                    all_nodes.append(item)
                elif item.get("type") == "relationship":
                    all_relationships.append(item)
            except json.JSONDecodeError:
                continue
    
    print(f"è¯»å–åˆ° {len(all_nodes)} ä¸ªèŠ‚ç‚¹å’Œ {len(all_relationships)} ä¸ªå…³ç³»")
    
    # ç¬¬äºŒæ­¥ï¼šå¤„ç†èŠ‚ç‚¹ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å…³ç³»ä¿¡æ¯ï¼‰
    print("\næ­£åœ¨å¤„ç†èŠ‚ç‚¹ï¼ˆåŒ…å«å…³ç³»ä¿¡æ¯ï¼‰...")
    node_count = 0
    for node in all_nodes:
        node_count += 1
        name = node.get("properties", {}).get("name")
        
        if not name:
            continue
            
        # ç”Ÿæˆå¢å¼ºçš„èŠ‚ç‚¹æ–‡æœ¬
        enhanced_text = enhance_node_with_relationships(node, all_relationships, all_nodes)
        if not enhanced_text:
            continue
        
        print(f"[{node_count}/{len(all_nodes)}] æ­£åœ¨å¤„ç†èŠ‚ç‚¹ '{name}'...")
        print(f"  ç”Ÿæˆçš„æ–‡æœ¬å—: {enhanced_text}")
        
        # ç”Ÿæˆå‘é‡å¹¶å‡†å¤‡æ’å…¥
        try:
            response = openai_client.embeddings.create(
                input=enhanced_text,
                model="text-embedding-3-small"
            )
            embedding = response.data[0].embedding
            documents_to_insert.append({'content': enhanced_text, 'embedding': embedding})
            time.sleep(0.1)
        except Exception as e:
            print(f"    -> ERROR: å¤„ç†èŠ‚ç‚¹ '{name}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    # ç¬¬ä¸‰æ­¥ï¼šå¤„ç†é‡è¦å…³ç³»ï¼ˆç”Ÿæˆç‹¬ç«‹çš„å…³ç³»æè¿°æ–‡æœ¬ï¼‰
    print("\næ­£åœ¨å¤„ç†é‡è¦å…³ç³»...")
    # ç”±äºæ•°æ®ä¸­åªæœ‰DEPENDS_ONå…³ç³»ï¼Œæˆ‘ä»¬å¤„ç†æ‰€æœ‰DEPENDS_ONå…³ç³»
    rel_count = 0
    processed_rel_types = set()
    
    for rel in all_relationships:
        rel_type = rel.get("label")
        if rel_type == "DEPENDS_ON":  # å¤„ç†æ‰€æœ‰DEPENDS_ONå…³ç³»
            rel_count += 1
            rel_text = generate_relationship_text(rel, all_nodes)
            
            if rel_text:
                start_name = rel.get("start", {}).get("properties", {}).get("name", "æœªçŸ¥")
                end_name = rel.get("end", {}).get("properties", {}).get("name", "æœªçŸ¥")
                rel_props = rel.get("properties", {})
                dependency_type = rel_props.get("type", "")
                processed_rel_types.add(dependency_type)
                
                print(f"[å…³ç³» {rel_count}] æ­£åœ¨å¤„ç†å…³ç³» '{start_name}' {rel_type} '{end_name}' (ç±»å‹: {dependency_type})...")
                
                try:
                    response = openai_client.embeddings.create(
                        input=rel_text,
                        model="text-embedding-3-small"
                    )
                    embedding = response.data[0].embedding
                    documents_to_insert.append({'content': rel_text, 'embedding': embedding})
                    time.sleep(0.1)
                except Exception as e:
                    print(f"    -> ERROR: å¤„ç†å…³ç³»æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    print(f"âœ… å¤„ç†äº† {rel_count} ä¸ªDEPENDS_ONå…³ç³»")
    print(f"ğŸ“Š å‘ç°çš„å…³ç³»ç±»å‹: {', '.join(processed_rel_types)}")
    
    # ç¬¬å››æ­¥ï¼šç”Ÿæˆå±‚æ¬¡ç»“æ„å’Œç±»å‹å…³ç³»æ–‡æ¡£
    print("\næ­£åœ¨ç”Ÿæˆå±‚æ¬¡ç»“æ„å’Œç±»å‹å…³ç³»æ–‡æ¡£...")
    hierarchy_docs = generate_hierarchy_and_type_documents(all_nodes, all_relationships)
    
    for doc in hierarchy_docs:
        try:
            response = openai_client.embeddings.create(
                input=doc,
                model="text-embedding-3-small"
            )
            embedding = response.data[0].embedding
            documents_to_insert.append({'content': doc, 'embedding': embedding})
            print(f"  ç”Ÿæˆå±‚æ¬¡ç»“æ„æ–‡æ¡£: {doc[:100]}...")
            time.sleep(0.1)
        except Exception as e:
            print(f"    -> ERROR: ç”Ÿæˆå±‚æ¬¡ç»“æ„æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    print(f"âœ… ç”Ÿæˆäº† {len(hierarchy_docs)} ä¸ªå±‚æ¬¡ç»“æ„å’Œç±»å‹å…³ç³»æ–‡æ¡£")
    
    # ç¬¬äº”æ­¥ï¼šåˆ†æ‰¹æ’å…¥æ‰€æœ‰æ•°æ®
    if documents_to_insert:
        print(f"\nä»»åŠ¡å®Œæˆ! å‡†å¤‡å°† {len(documents_to_insert)} ä¸ªæ–‡æ¡£åˆ†æ‰¹æ’å…¥åˆ°Supabase...")
        
        # åˆ†æ‰¹å¤§å°
        batch_size = 50
        total_inserted = 0
        
        try:
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(documents_to_insert), batch_size):
                batch = documents_to_insert[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                total_batches = (len(documents_to_insert) + batch_size - 1) // batch_size
                
                print(f"æ­£åœ¨æ’å…¥ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch)} æ¡è®°å½•)...")
                
                response = supabase.table('ue_documents').insert(batch).execute()
                
                if response.data:
                    total_inserted += len(response.data)
                    print(f"âœ… ç¬¬ {batch_num} æ‰¹æ’å…¥æˆåŠŸï¼å·²ç´¯è®¡æ’å…¥ {total_inserted} æ¡è®°å½•")
                else:
                    print(f"âš ï¸ ç¬¬ {batch_num} æ‰¹æ’å…¥å®Œæˆï¼Œä½†æœªè¿”å›æ•°æ®")
                    if hasattr(response, 'error') and response.error:
                        print(f"é”™è¯¯ä¿¡æ¯: {response.error}")
                
                # åœ¨æ‰¹æ¬¡ä¹‹é—´ç¨ä½œåœé¡¿
                if i + batch_size < len(documents_to_insert):
                    time.sleep(1)
            
            print(f"ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡æ’å…¥å®Œæˆï¼æ€»å…±æˆåŠŸæ’å…¥ {total_inserted} æ¡è®°å½•ã€‚")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æ’å…¥æ•°æ®åº“æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            print("ğŸ’¡ å»ºè®®ï¼šå¦‚æœè¿˜æ˜¯è¶…æ—¶ï¼Œå¯ä»¥å°è¯•å‡å° batch_size çš„å€¼")
    else:
        print("æ²¡æœ‰æ‰¾åˆ°å¯ä»¥å¤„ç†çš„èŠ‚ç‚¹æ•°æ®ã€‚")

# æ‰§è¡Œä¸»å‡½æ•°
if __name__ == '__main__':
    script_dir = os.path.dirname(os.path.abspath(__file__))
    json_path = os.path.join(script_dir, "unreal_engine_graph.json")
    
    if os.path.exists(json_path):
        migrate_data(json_path)
    else:
        print(f"é”™è¯¯ï¼šåœ¨æŒ‡å®šè·¯å¾„æ‰¾ä¸åˆ°æ–‡ä»¶ '{json_path}'ã€‚")